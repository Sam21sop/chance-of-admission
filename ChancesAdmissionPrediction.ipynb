{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1k_PCaMxuXr5313VyEnj13lvqEBWj9tqE",
      "authorship_tag": "ABX9TyOoD31EFEbQCkUsYA7CRF5/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "m8QeRbxzAaxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tabula-py\n"
      ],
      "metadata": {
        "id": "65lhdCdyNB2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "gli6YAGkOvwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdrv4Ns1AGLw"
      },
      "outputs": [],
      "source": [
        "# prompt: To convert PDF files to CSV files in Python, you can use the tabula-py library for extracting tables from PDFs and the pandas library for working with dataframes.\n",
        "\n",
        "import tabula\n",
        "import pandas as pd\n",
        "\n",
        "# Load the PDF file\n",
        "pdf_file = '/content/1.pdf'\n",
        "\n",
        "# Extract tables from the PDF\n",
        "tables = tabula.read_pdf(pdf_file, pages='all')\n",
        "\n",
        "# Convert the tables to pandas dataframes\n",
        "df = pd.concat(tables)\n",
        "\n",
        "# Save the dataframe to a CSV file\n",
        "df.to_csv('output.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tabula import read_pdf\n",
        "\n",
        "def convert_pdf_to_csv(pdf_path, csv_path):\n",
        "    # Use tabula to extract tables from the PDF\n",
        "    tables = read_pdf(pdf_path, pages='all', multiple_tables=True)\n",
        "\n",
        "    # Assuming you want to save all tables from the PDF into a single CSV file\n",
        "    combined_df = pd.concat(tables, ignore_index=False)\n",
        "\n",
        "    # Save the combined dataframe to a CSV file\n",
        "    combined_df.to_csv(csv_path, index=False)\n",
        "    print(f\"Converted: {pdf_path} to {csv_path}\")\n",
        "\n",
        "def convert_all_pdfs_to_csv(folder_path):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.pdf'):\n",
        "            # Construct the full paths for the PDF and CSV files\n",
        "            pdf_path = os.path.join(folder_path, file)\n",
        "            csv_name = os.path.splitext(file)[0] + '.csv'\n",
        "            csv_path = os.path.join(folder_path, csv_name)\n",
        "\n",
        "            # Convert the PDF to CSV\n",
        "            convert_pdf_to_csv(pdf_path, csv_path)\n",
        "\n",
        "# Specify the folder path containing the PDF files\n",
        "folder_path = '/content/sample_data/PDF'\n",
        "\n",
        "# Call the function to convert all PDF files to CSV in the folder\n",
        "convert_all_pdfs_to_csv(folder_path)\n"
      ],
      "metadata": {
        "id": "3Oh1tQpANq-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: To concatenate all CSV files into a single CSV file in Python\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# List all CSV files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate through each CSV file\n",
        "for file in files:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df_temp = pd.read_csv(os.path.join(folder_path, file))\n",
        "\n",
        "    # Concatenate the DataFrame with the empty DataFrame\n",
        "    df = pd.concat([df, df_temp], ignore_index=True)\n",
        "\n",
        "# Save the concatenated DataFrame to a new CSV file\n",
        "df.to_csv('output.csv', index=False)\n"
      ],
      "metadata": {
        "id": "28qmw0q3RdMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def concatenate_csv_files(folder_path, output_csv):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Initialize an empty DataFrame to store the combined data\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            # Construct the full path for the CSV file\n",
        "            csv_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Read the CSV file into a DataFrame\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Concatenate the DataFrame to the combined DataFrame\n",
        "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a single CSV file\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Combined all CSV files into: {output_csv}\")\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# Specify the output CSV file\n",
        "output_csv = 'output_combined.csv'\n",
        "\n",
        "# Call the function to concatenate all CSV files into a single CSV file\n",
        "concatenate_csv_files(folder_path, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF66afmJThQK",
        "outputId": "c6a09ec5-3350-4972-a057-7a2c2f020c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined all CSV files into: output_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def add_table_heading(csv_path):\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Check if the required columns are already present\n",
        "    required_columns = [\"sr_no\", \"College_name\", \"cutoff\"]\n",
        "    missing_columns = set(required_columns) - set(df.columns)\n",
        "\n",
        "    # Add missing columns with NaN values\n",
        "    for column in missing_columns:\n",
        "        df[column] = float('nan')\n",
        "\n",
        "    # Save the updated DataFrame back to the CSV file\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "def concatenate_csv_files(folder_path, output_csv):\n",
        "    # List all files in the folder\n",
        "    files = os.listdir(folder_path)\n",
        "\n",
        "    # Initialize an empty DataFrame to store the combined data\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each file\n",
        "    for file in files:\n",
        "        if file.endswith('.csv'):\n",
        "            # Construct the full path for the CSV file\n",
        "            csv_path = os.path.join(folder_path, file)\n",
        "\n",
        "            # Add table heading/features to each CSV file\n",
        "            add_table_heading(csv_path)\n",
        "\n",
        "            # Read the CSV file into a DataFrame\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            # Concatenate the DataFrame to the combined DataFrame\n",
        "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "    # Save the combined DataFrame to a single CSV file\n",
        "    combined_df.to_csv(output_csv, index=False)\n",
        "    print(f\"Combined all CSV files into: {output_csv}\")\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/sample_data/CSV'\n",
        "\n",
        "# Specify the output CSV file\n",
        "output_csv = 'output_combined.csv'\n",
        "\n",
        "# Call the function to concatenate all CSV files into a single CSV file\n",
        "concatenate_csv_files(folder_path, output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA8LAjn5TxIv",
        "outputId": "8d0dba89-2595-4c72-8e6a-ca41eeb409e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined all CSV files into: output_combined.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8wVX3b6OUpLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chance of Admit Using linear Regression**\n"
      ],
      "metadata": {
        "id": "nsNbP_ba2Oy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Student Data"
      ],
      "metadata": {
        "id": "7GfVH7Y43PEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Ks-nirzL2aKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Admission_Predict.csv\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "aiK9EMtH3l3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "oxYi5rZj4wzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chance of Admit** is target variable/feature/attribute\n",
        "\n",
        "Except all are predictor"
      ],
      "metadata": {
        "id": "5cjjgEdm64qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "0i6VGbzF53db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "65BtB_9u7wsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nZT4IRcW8DJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "UzPgYWVD8hg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# missing value\n",
        "df.isnull()"
      ],
      "metadata": {
        "id": "VRoiWotM8kHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "yZgEXe5j8ppW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identify remove outlier\n",
        "# oulier visualization\n",
        "df.boxplot(column = [\"Chance of Admit \"])"
      ],
      "metadata": {
        "id": "snIRfOZc80zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# oulier visualization\n",
        "df.boxplot(column = [\"GRE Score\", \"TOEFL Score\"])"
      ],
      "metadata": {
        "id": "SSnanYMG9eNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w12GRiBr9tx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Model"
      ],
      "metadata": {
        "id": "DXLq2CSYGr6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#separating independant and dependent variable\n",
        "x = df.drop([\"Chance of Admit \"], axis=1)\n",
        "y = df[\"Chance of Admit \"]\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTgXXn_1GuB3",
        "outputId": "48f5faee-31dc-43e9-9570-5280f9f67675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((400, 8), (400,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=56) # by default training data will be 80% and testing data 20%"
      ],
      "metadata": {
        "id": "i6u_np5XHSFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model selection and Training"
      ],
      "metadata": {
        "id": "cf_YTSKVIjyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error as MAE"
      ],
      "metadata": {
        "id": "LSklbeLRIMcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating instance of linear regression\n",
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "lGhQv0MnI7Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "lr.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "gou9MHq1I-FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction From Model"
      ],
      "metadata": {
        "id": "De-EtBdBJ7l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predictiong over train set\n",
        "train_prediction = lr.predict(x_train)\n",
        "train_score = np.sqrt(MAE(train_prediction, y_train))\n",
        "print(f\"Traning Score: {train_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjNnhwLiJqVz",
        "outputId": "c6f78265-243e-42be-87d4-ab45765ad378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traning Score: 0.21077399950624928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictiong over train set\n",
        "test_prediction = lr.predict(x_test)\n",
        "test_score = np.sqrt(MAE(test_prediction, y_test))\n",
        "print(f\"Testing Score: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehizU5ouMBl0",
        "outputId": "2f52f165-32f4-4f81-eabd-a3c95d9907c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Score: 0.21185659942151241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05lO4EkSMm0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "b3HvGZsSMvcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = lr.score(x_test, y_test) * 100\n",
        "train = lr.score(x_train, y_train) * 100\n"
      ],
      "metadata": {
        "id": "5BQk0J-2Mz3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test)\n",
        "print(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpTECKNgOGwu",
        "outputId": "628786b4-1097-48cc-c053-236903a25750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82.39312119935536\n",
            "81.4457945799909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsYRcDA_OLyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging Multiple Tables"
      ],
      "metadata": {
        "id": "gguxUepZyF57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: concatenate more multiple csv file along with columns\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the folder path containing the CSV files\n",
        "folder_path = '/content/csvs'\n",
        "\n",
        "# List all CSV files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Create an empty DataFrame\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate through each CSV file\n",
        "for file in files:\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df_temp = pd.read_csv(os.path.join(folder_path, file))\n",
        "\n",
        "    # Concatenate the DataFrame with the empty DataFrame\n",
        "    df = pd.concat([df, df_temp], ignore_index=True)\n",
        "\n",
        "print(df.head(20))\n",
        "# Save the concatenated DataFrame to a new CSV file\n",
        "df.to_csv('final_dataset.csv', index=True)\n"
      ],
      "metadata": {
        "id": "i-_2je__yP_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BuBp2WyI5hBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing Data In SQLite"
      ],
      "metadata": {
        "id": "ETHntFYw8-ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: store a csv file in the SQLite database\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('colleges_data.db')\n",
        "\n",
        "# Create a cursor to execute SQL statements\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table to store the data\n",
        "cursor.execute('''CREATE TABLE Student_data (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    sr_num INTEGER,\n",
        "    college_name TEXT,\n",
        "    cut_off INTEGER\n",
        ")''')\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/final_dataset.csv')\n",
        "\n",
        "# Insert the data from the DataFrame into the table\n",
        "cursor.executemany('INSERT INTO Student_data VALUES (?, ?, ?, ?)', df.values.tolist())\n",
        "\n",
        "# Commit the changes to the database\n",
        "conn.commit()\n",
        "\n",
        "# Close the connection to the database\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "Rw7rPiOU9FMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: fetch the data from SQLite3 and display in the form of table\n",
        "\n",
        "# Import the necessary libraries\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('colleges_data.db')\n",
        "\n",
        "# Create a cursor to execute SQL statements\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch all the data from the table\n",
        "cursor.execute('SELECT * FROM Student_data')\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "df = pd.DataFrame(cursor.fetchall())\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df.head(20))\n",
        "\n",
        "# Close the connection to the database\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "shJJntfN9cb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: delete \"sr_num\" column from colleges_data.db\n",
        "\n",
        "# Import the necessary libraries\n",
        "import sqlite3\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('colleges_data.db')\n",
        "\n",
        "# Create a cursor to execute SQL statements\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Delete the \"sr_num\" column from the table\n",
        "cursor.execute('ALTER TABLE Student_data DROP COLUMN sr_num')\n",
        "\n",
        "# Commit the changes to the database\n",
        "conn.commit()\n",
        "\n",
        "# Close the connection to the database\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "dmAzwu6WAhe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing\n"
      ],
      "metadata": {
        "id": "w4WkttPfOq1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "\n",
        "#Step 2: import data\n",
        "df = pd.read_csv('/content/admission_predict.csv')"
      ],
      "metadata": {
        "id": "MeWnN_HnxDe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data visualization\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdMcKkVUxF-9",
        "outputId": "ffb00455-a8e1-4a9e-8562-c1edaf2a87f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
              "       'LOR ', 'CGPA', 'Research', 'Chance of Admit'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define X(features) and Y(Target)\n",
        "y = df['Chance of Admit']\n",
        "x = df[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']]\n",
        "\n",
        "# Step 4: train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.3,random_state = 9598)"
      ],
      "metadata": {
        "id": "x9gQKyZZjFk8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression model"
      ],
      "metadata": {
        "id": "wv4FsX-xzYa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model selection\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "# it is the step where the actually machine learning\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n"
      ],
      "metadata": {
        "id": "-HO3ZxSjxfuK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 8: Calculate the Accuracy of the Model\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error,mean_squared_error\n",
        "\n",
        "error = mean_absolute_error(y_test,y_pred)\n",
        "percentageError = mean_absolute_percentage_error(y_test, y_pred)\n",
        "modelAccuracy = (1 - percentageError) * 100\n",
        "\n",
        "\n",
        "print(f'Model Error: {error}')\n",
        "print(f'Percentage Error: {percentageError}')\n",
        "print(f'Model Accuracy: {modelAccuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1DnwjBty7p",
        "outputId": "01cc2601-ad22-449a-9752-d1a0e17679c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Error: 0.041375892057603066\n",
            "Percentage Error: 0.06789110722674732\n",
            "Model Accuracy: 93.21088927732526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHa34TWjx0PU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}